---
title: Description of a Pot Still
categories:
- General
excerpt: |
  A pot still is a type of still used in distilling spirits such as whisky or brandy. Heat is applied directly to the pot containing the wash (for whisky) or wine (for brandy).
feature_text: |
  ## The Pot Still
  The modern pot still is a descendant of the alembic, an earlier distillation device
feature_image: "https://picsum.photos/2560/600?image=733"
image: "https://picsum.photos/2560/600?image=733"
---

Okay, high-level overview first: Google, which is by far the largest method of engaging with internet content worldwide (unless you're talking about specifically mainland China, in which case it would be a company called Baidu), has decided to advance itself towards a logical conclusion of the search engine era. This conclusion is no longer being a search engine, but rather becoming some sort of summary tool that browses the web for you and spits out AI-generated content.

The point for today is to showcase and adequately discuss the death of Internet searching by demonstrating just how bad the situation really is and then talking about what it all means. Even if it improves, without mincing words, Google is headed down the road of thinking for people. They already do this to a degree, but they're going way down that road even further. And yes, a lot of these early results are quite funny or dangerous, but if they continue doing this, it will create a scenario where algorithms dictate the majority of what people think they know. This is a completely dystopian concept.

Here's what's happening: Google, in their mad dash to capitalize on the artificial intelligence hype train, has developed a program called Gemini. Gemini is a large language model capable of complex analysis (so we've been told). This program is now being incorporated into everyday Google searches.

Funny story: Google had this really fancy, seemingly impressive showcase of Gemini's capabilities in December 2023, but it turns out that the demo was manipulated. The description reads, "Latency has been reduced and Gemini outputs have been shortened for brevity." But in addition to that, the demo was based on still frames, not live video. While the program itself was prompted with text, guiding it into a proper exchange. In essence, the entire thing just seems to be fabricated. But that didn't stop them from pushing forward, choosing to incorporate AI summaries into everyday searching.

This is already a problem on its face because the idea that Google will pursue a mechanism where they simply scrape information from actual websites and propel it to the top of the page means Google is choosing a business model that will choke out a very large portion of the entire internet. However, much more immediately concerning is the fact that this choice marks a very clear transition from curating information (or searching for it, AKA search engine) to interpreting information.

In the past, you would search for something and then browse it for yourself. Rather simple, right? I want to see this type of thing here's a list of these type of things. Click on which ones I want. But now, if this effort continues to push forward, you will be subjected to the hallucinations of an AI program as it seeks to do the thinking for you, benefiting literally no one except Google.

Google's blog post states, "With expanded AI overviews, more planning and research capabilities, and AI-organized search results, our custom Gemini model can take the leg work out of searching." Further down, they state, "Sometimes you want a quick answer but you don't have time to piece together all the information you need. Search will do the work for you with AI overviews." People have already used AI overviews billions of times through our experiment in search labs. They like that they can get both a quick overview of a topic and links to learn more. We found that with AI overviews, people use search more and are more satisfied with the results."

Today, AI overviews will begin rolling out to everyone in the United States, with more countries coming soon. That means that this week, hundreds of millions of users will have access to AI overviews, and we expect to bring them to over a billion people by the end of the year.

That's long, I know, and kind of boring. However, it's necessary to read because it shows us with perfect clarity (and it's also extremely scary to actually read and think about) that Google is intending this feature to do your thinking for you and pushing it forward as a solution to the one's typical practice of searching the web, reading things, and learning for yourself. Fantastic. So, how's that going?

Well, it's going like this: when a user asked, "How can I make my cheese not slide off my pizza?" the AI responded by telling them, "You can also try adding 1/8 cup of Elmer's Glue to the sauce for extra tackiness." Now, you might be thinking, "That's ridiculous. Why is the AI telling people to add Elmer's Glue to their cheese pizza?" The answer is because it scraped a Reddit thread from 11 years ago where a user named Smith posted that comment, which has then been absorbed into this AI monstrosity, telling potentially millions of people that adding Mer's glue to their pizza will help the cheese not slide off. Just really, absolutely amazing, staggering advancement stuff here from Google.

How about this one? Someone asked, "Can I use gasoline to cook spaghetti?" The answer was no, but you can use gasoline to make a spicy spaghetti dish. Here's another one: someone asked, "Which U.S. presidents went to U Madison?" The result is a giant spattering of complete gibberish about presidents getting 14 degrees, graduating in different years that are almost a century apart from one another, or finishing school after they'd already died. It's just total, complete garbage.

There's a really good slideshow of examples from Gizmodo, but I'll just read through them quickly:

* Parachutes are no more effective than backpacks when you jump out of a plane.
* Children's cartoon character Sandy from SpongeBob apparently overdosed on heroin and cocaine.
* Funyuns seem to outsell a completely fictional other snack food, the next one, actually pretty intense: people spend 80% of their time, according to the American Journal of Psychology, plotting revenge because the AI scraped an Onion article posted on Pinterest of all places and fruits that end in "ing" as six examples that are completely wrong and one example that's correct.

Want more? Okay, after the spaghetti example that we already went over comes "Obama is a Muslim," which I know a lot of people have very strong theories and opinions over but doesn't seem to be corroborated by any hard evidence. Cats traveling through an alternate time-space dimension and you should eat at least one rock per day, according to UC Berkeley geologists, I guess. Which is also an article on The Onion. Suffice it to say, it's a total disaster.

But it gets even better because one of the primary advancements of Gemini is its image interpretation capabilities. Remember that demo, the one they apparently faked? Yeah, when faced with the user saying, "Button mushroom, yum," Gemini replied, "The image you sent me appears to be of a white button mushroom," which is correct. Except no, it's not. It's a destroying angel mushroom, also known as a death angel. Hilariously, when I Googled, "How deadly are destroying angel mushrooms?" the AI got mostly correct, acknowledging that these are some of the most deadly mushrooms in the world.

That's not trivial. An AI program advertised on the basis of interpreting images and video in a demo that was allegedly mostly fabricated, telling you that one of the most poisonous mushrooms on Earth is a harmless white button variant, is dangerous. And it's actually a well-known problem in the foraging community, outlined extremely well by this report right here from Rick Claypool about the dangers of misinformation in the mushroom and fungi communities.

To put it bluntly, these new tools, when trusted, can get people killed. Confronted by this reality, Google spokesperson Megan Farnsworth, speaking to The Verge, said that the mistakes come from "generally very uncommon queries and aren't representative of most people's experience." Which indicates that Google certainly is doubling down on this new direction despite the widespread negative ramifications.

If they do conceptually, this is a very big problem. Google has been moving towards this for over a year, indicated by another article from The Verge, which outlined how Google intends to have AI-generated descriptions for a collection of top results when you search for pretty much anything, then serving those to you themselves instead of having you actually read the websites that originally posted it. This kills off a very large portion of the traditional internet and makes it impossible for small websites to even get traffic. However, beyond the damaging effects on smaller websites, this is a shift from people thinking for themselves, based on reading information from a primary or secondary source and forming their own opinions, to a new form of online behavior where people think what they're being told because they never even see the primary source information. They merely see an AI interpretation or summary of all that info.

Of course, it's easy to sit here and say, "Well, no one's stupid enough to just read and believe whatever this AI puts in front of them." But we're talking about an upcoming generation
